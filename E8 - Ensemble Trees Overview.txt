Dentro de los árboles de decisión, el método de Ensemble resulta ser una estrategia bastante interesante dado que permite realizar modelos más robustos a la hora de realizar labores de clasificación. Este método toma como punto de partida, el análisis individual de diferentes modelos donde al final empleando diferentes métodos, estos terminan uniéndose a fin de generar una predicción mucho más estable a diferencia de que si se realizaran modelos individuales.
Los motivos para realizar este procedimiento se distinguen de la siguiente forma:
•	Evita la dependencia de modelos individuales pudiéndose ponderar la relación de cada modelo a fin de generar u mejor resultado el cual no se podría obtener de manera individual.
•	Reduce el error generado al analizar modelos de predicción y clasificación empleados de manera individual, dado que una predicción generada por este método tiende a que se reduzca el error al ponderar los errores de cada modelo haciendo que de esta forma este sea como se dijo anteriormente más robusto a la hora de generar una predicción. 
Dependiendo del resultado que se quiera generar el análisis de la información se puede generar dos tipos de ensambles los cuales son Homogéneos y heterogéneos, en el caso de los estimadores homogéneos se busca emplear modelos iguales los cuales permitan a fin de generar un análisis mucho más rápido de la información. Mientras por el lado de los modelos heterogéneos se busca ensamblar diferentes funciones a fin de aumentar la precisión del modelo a analizar a fin de aprovechar las ventajas de cada modelo empleado para realizar la predicción.
Dentro de los modelos que se pueden emplear para realizar este método podemos encontrar:
•	Bagging: Reduce la varianza del estimado combinando múltiples estimadores 
•	Boosting: una familia de algoritmos que permiten reforzar modelos de predicción que por lo general de manera individual son débiles 
•	Stacking: Combina múltiples clasificadores o modelos de regresión a partir de meta clasificadores o meta modelos. Esto nos indica que los modelos base dentro de este algoritmo se entrenan con la base total y después el meta modelo es entrenado con los resultados de los algoritmos bases.
